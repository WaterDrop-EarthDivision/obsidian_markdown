---
{"dg-publish":true,"permalink":"/pytorch/argparse-argument-parser/","dgPassFrontmatter":true,"created":"2025-10-24T20:30:11.732+08:00","updated":"2025-12-26T14:58:29.612+08:00"}
---



```python
Â  Â  parser = argparse.ArgumentParser()
Â  Â  parser.add_argument('--batch_size', default=64, type=int, required=False, help='batch size')
Â  Â  parser.add_argument('--lr', default=1e-3, type=float, required=False, help='learn rate')
Â  Â  parser.add_argument('--alpha', default=1, type=int, required=False, help='soft loss')
Â  Â  # | --alpha | 1 | int | è½¯æŸå¤±æƒé‡ç³»æ•°ï¼Œç”¨äºåŠ æƒè’¸é¦æŸå¤±ï¼ˆKL æ•£åº¦ï¼‰å’Œç¡¬æŸå¤±ï¼ˆå¦‚ CEï¼‰ã€‚
Â  Â  # ä½†åœ¨ä½ çš„ä»£ç ä¸­ï¼š
Â  Â  # loss = soft_loss * args.alpha
Â  Â  # å› ä¸º alpha=1ï¼Œæ‰€ä»¥åªç”¨äº†è½¯æŸå¤±ï¼ˆKL æ•£åº¦ï¼‰ï¼Œæ²¡æœ‰ç¡¬ä»»åŠ¡æŸå¤±ã€‚
Â  Â  # ğŸ“Œ å¦‚æœä½ æƒ³åšæ··åˆæŸå¤±ï¼Œåº”æ”¹ä¸º float ç±»å‹ï¼Œæ¯”å¦‚ alpha=0.7 |
Â  Â  # parser.add_argument('--max_grad_norm', default=1.0, type=float, required=False)
Â  Â  parser.add_argument('--top_k', default=10, type=int, required=False, help='top k sampling') Â # ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œåªä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ªè¯ä¸­é‡‡æ ·
Â  Â  parser.add_argument('--top_p', default=1.0, type=float, required=False, help='top p sampling') Â # ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œåªä»ç´¯è®¡æ¦‚ç‡è¶…è¿‡ P çš„è¯ä¸­é‡‡æ · å¸¸ä¸ top_k äºŒé€‰ä¸€ä½¿ç”¨ï¼Œå…¸å‹å€¼ï¼š0.9, 0.95 | Â ç›¸å½“äºä¸é™åˆ¶
Â  Â  parser.add_argument('--sigma', default=15, type=float, required=False, help='the weight of score') Â #
Â  Â  parser.add_argument('--n_steps', default=10000, type=float, required=False, help='the weight of score') Â # è®­ç»ƒæ€»æ­¥æ•°
Â  Â  parser.add_argument('--n_tokens', default=10, type=int, required=False, help='soft embedding') # è½¯æç¤ºï¼ˆSoft Promptï¼‰çš„é•¿åº¦ï¼Œå³åœ¨è¾“å…¥å‰æ·»åŠ å¤šå°‘ä¸ªå¯å­¦ä¹ çš„è¿ç»­å‘é‡ã€‚
Â  Â  
	args =parser.parse_args()
	print("Args:", args)
```

```bash
python train.py --batch_size 32 --lr 5e-4 --alpha 0.7 --top_k 50 --top_p 0.9 --sigma 20 --n_steps 20000 --n_tokens 20
```

